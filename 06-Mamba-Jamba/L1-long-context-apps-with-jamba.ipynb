{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5112014",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.16.1\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d34188",
   "metadata": {},
   "source": [
    "# Lab: Build Long-Context AI Apps with Jamba\n",
    "\n",
    "**Goal:** In this lab, you will experience the power of a long-context AI model. You will use a model like Jamba to process a lengthy, domain-specific documentâ€”something that would be difficult for a standard model with a small context window.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Long-Context Processing:** Understanding the challenges and benefits of working with large amounts of text at once.\n",
    "- **Hybrid Architecture (Jamba):** Appreciating how combining Transformer and Mamba blocks enables efficient long-context processing.\n",
    "- **Summarization and Q&A over entire documents.**\n",
    "\n",
    "**Note:** We will be using the OpenAI API for this lab, which may not have Jamba specifically, but we can simulate the experience by using their best long-context model (e.g., `gpt-4-turbo`) which can handle large context windows. The principles remain the same.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "First, let's install the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d6719",
   "metadata": {
    "title": "# %pip install openai python-dotenv"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd4206f",
   "metadata": {},
   "source": [
    "## 2. Loading the Document\n",
    "\n",
    "The core of this lab is our source document on \"Quality by Design (QbD)\". It's a comprehensive overview that is too long for many standard models to handle in a single pass. Let's load it into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f168cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"data/quality_by_design_overview.txt\", \"r\") as f:\n",
    "        qbd_document_text = f.read()\n",
    "    print(\"Successfully loaded the 'Quality by Design' document.\")\n",
    "    print(f\"Document length: {len(qbd_document_text.split())} words\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure 'data/quality_by_design_overview.txt' exists.\")\n",
    "    qbd_document_text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261bcdb4",
   "metadata": {},
   "source": [
    "## 3. The Power of Long Context: Full Document Summarization\n",
    "\n",
    "With a traditional model (e.g., 4k context window), summarizing this document would require complex techniques like \"Map-Reduce,\" where you summarize chunks and then summarize the summaries. This often leads to a loss of context and nuance.\n",
    "\n",
    "With a long-context model, we can feed the entire document in a single prompt.\n",
    "\n",
    "### Exercise 1: Generate a High-Level Summary\n",
    "\n",
    "**Your Task:** Write a prompt that asks the AI to provide a high-level, one-paragraph summary of the entire document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33862784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PROMPT HERE\n",
    "summary_prompt = f\"\"\"\n",
    "# Please provide a concise, one-paragraph executive summary of the following document on Quality by Design (QbD).\n",
    "#\n",
    "# --- DOCUMENT ---\n",
    "# {qbd_document_text}\n",
    "# --- END DOCUMENT ---\n",
    "# \"\"\"\n",
    "#\n",
    "# if qbd_document_text:\n",
    "#     print(\"Generating summary...\")\n",
    "#     summary = get_completion(summary_prompt)\n",
    "#     print(\"\\n--- Executive Summary ---\")\n",
    "#     print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b9b67",
   "metadata": {},
   "source": [
    "### Exercise 2: Structured Extraction from the Full Document\n",
    "\n",
    "A simple summary is useful, but the real power comes from extracting specific, structured information from the entire text at once.\n",
    "\n",
    "**Your Task:** Write a prompt that asks the AI to identify and list all the **Core Elements of Quality by Design** mentioned in the text. The output should be a numbered list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb586a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR PROMPT HERE\n",
    "structured_extraction_prompt = f\"\"\"\n",
    "# Based on the document provided below, please identify and list the core elements of Quality by Design (QbD).\n",
    "# The output should be a numbered list, with a brief one-sentence description for each element based on the text.\n",
    "#\n",
    "# --- DOCUMENT ---\n",
    "# {qbd_document_text}\n",
    "# --- END DOCUMENT ---\n",
    "# \"\"\"\n",
    "#\n",
    "# if qbd_document_text:\n",
    "#     print(\"Extracting core elements...\")\n",
    "#     core_elements = get_completion(structured_extraction_prompt)\n",
    "#     print(\"\\n--- Core Elements of QbD ---\")\n",
    "#     print(core_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dd7e45",
   "metadata": {},
   "source": [
    "## 4. Full-Context Question Answering\n",
    "\n",
    "Long context allows for sophisticated question-answering where the model can synthesize information from different parts of the document to form a coherent answer.\n",
    "\n",
    "### Exercise 3: Answering a Complex Question\n",
    "\n",
    "**Your Task:** Ask a question that requires the model to connect at least two different concepts from the text. For example, ask how Risk Assessment relates to the Control Strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f4cb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR QUESTION HERE\n",
    "complex_question = f\"\"\"\n",
    "# According to the provided document, how does the 'Risk Assessment' phase influence the 'Control Strategy' in a Quality by Design framework?\n",
    "#\n",
    "# --- DOCUMENT ---\n",
    "# {qbd_document_text}\n",
    "# --- END DOCUMENT ---\n",
    "# \"\"\"\n",
    "#\n",
    "# if qbd_document_text:\n",
    "#     print(f\"Asking complex question: {complex_question.splitlines()[1]}\")\n",
    "#     answer = get_completion(complex_question)\n",
    "#     print(\"\\n--- AI's Answer ---\")\n",
    "#     print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb42275",
   "metadata": {},
   "source": [
    "### Why this is better than RAG (Retrieval-Augmented Generation) in some cases:\n",
    "\n",
    "For RAG, you would embed chunks of the document, find the most relevant chunks, and then feed only those to the model. This is great for very large document sets.\n",
    "\n",
    "However, if a question requires synthesizing information from the *introduction* and the *conclusion* of a document, RAG might fail to retrieve both chunks. A long-context model sees the entire document and can make these connections seamlessly.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you have seen the practical benefits of modern, long-context AI architectures like Jamba. By being able to process entire documents in a single pass, you can perform tasks that were previously much more complex or impossible:\n",
    "\n",
    "1.  **Holistic Summarization:** Creating summaries that capture the full context of the document.\n",
    "2.  **Complex Q&A:** Answering questions that require synthesizing information from multiple sections.\n",
    "3.  **Simplified Workflows:** Avoiding the need for complex chunking and map-reduce logic.\n",
    "\n",
    "As these models become more widespread, the ability to build applications that leverage long-context understanding will be a critical skill."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
