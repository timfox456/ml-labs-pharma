{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32e1d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- \n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.16.1\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97a80b2",
   "metadata": {},
   "source": [
    "# Lab: Build a Compliant AI Workflow for QC Reports\n",
    "\n",
    "**Goal:** In this lab, you will build a simplified but compliant workflow for analyzing a lab report using an AI model. The focus is not on the AI's accuracy, but on the **governance and traceability** required in a regulated GxP environment. \n",
    "\n",
    "**Key Concepts:**\n",
    "- **Audit Trails:** Understanding the \"who, what, when, and why\" of every action.\n",
    "- **Versioning:** Treating prompts and models as controlled documents.\n",
    "- **Human-in-the-Loop (HITL):** Ensuring a qualified person makes the final decision. \n",
    "- **Electronic Signatures:** Securely associating a person with an action. \n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "We'll need pandas to interact with our CSV-based audit log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3761a6b0",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "import getpass  # To simulate getting the current user\n",
    "\n",
    "# Define the path to our audit log\n",
    "AUDIT_LOG_PATH = \"data/audit_log.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681c37c",
   "metadata": {},
   "source": [
    "## 2. The Scenario\n",
    "\n",
    "Imagine you are a QC analyst. A new lab report has come in for Batch `AP-2024-03-25-B004`. Your task is to use an AI assistant to analyze this report for potential issues and then formally approve or reject the AI's analysis. \n",
    "\n",
    "Every significant action you take must be logged in the `audit_log.csv` file, creating an unbreakable chain of evidence that would satisfy an auditor. \n",
    "\n",
    "### Our \"Database\": The Audit Log\n",
    "Let's create a helper function to write events to our CSV file. In a real system, this would be a validated database that complies with 21 CFR Part 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d8d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_event(event_type: str, user: str, prompt_version: str = \"N/A\", batch_id: str = \"N/A\", details: str = \"\", signature: str = \"N/A\"):\n",
    "    \"\"\"\n",
    "    Appends a new event to the audit log.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new record\n",
    "        new_log_entry = pd.DataFrame([{\n",
    "            \"timestamp\": datetime.utcnow().isoformat(),\n",
    "            \"event_type\": event_type,\n",
    "            \"user\": user,\n",
    "            \"prompt_version\": prompt_version,\n",
    "            \"batch_id\": batch_id,\n",
    "            \"details\": details,\n",
    "            \"signature\": signature\n",
    "        }])\n",
    "        \n",
    "        # Append to the CSV file\n",
    "        new_log_entry.to_csv(AUDIT_LOG_PATH, mode='a', header=False, index=False)\n",
    "        print(f\"Event logged: {event_type}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to log event: {e}\")\n",
    "\n",
    "# Let's simulate a user login event\n",
    "current_user = getpass.getuser()\n",
    "log_event(\"USER_LOGIN\", user=current_user, details=\"User logged into the system.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b79d52",
   "metadata": {},
   "source": [
    "## 3. Versioning the Prompt\n",
    "\n",
    "In a compliant system, you can't just use any prompt. The prompt itself must be version-controlled. A change to the prompt could change the AI's output, so auditors need to know *exactly* which prompt was used. \n",
    "\n",
    "We will simulate this by creating a \"Prompt Library.\" In a real system, this would be a validated document management system or a Git repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our \"Prompt Library\"\n",
    "PROMPT_LIBRARY = {\n",
    "    \"v1.0.0\": \"Analyze the following lab report and summarize any potential deviations or out-of-spec results.\",\n",
    "    \"v1.1.0\": \"Analyze the following lab report. Summarize any potential deviations or out-of-spec results. Also, highlight any results that are within 5% of their specification limit.\"\n",
    "}\n",
    "\n",
    "# We will use the latest, approved version for our analysis.\n",
    "ACTIVE_PROMPT_VERSION = \"v1.1.0\"\n",
    "ACTIVE_PROMPT = PROMPT_LIBRARY[ACTIVE_PROMPT_VERSION]\n",
    "\n",
    "print(f\"Using Prompt Version: {ACTIVE_PROMPT_VERSION}\")\n",
    "print(f\"Prompt Text: '{ACTIVE_PROMPT}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ef324",
   "metadata": {},
   "source": [
    "## 4. Simulating the AI Analysis\n",
    "\n",
    "Now, we'll run our \"AI analysis.\" For this lab, we will **simulate** the AI's output to focus on the workflow. In a real application, you would call the LLM here, similar to the previous lab. \n",
    "\n",
    "The key is that we **log the interaction**. We record who ran the analysis, on which batch, and with which prompt version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3513a477",
   "metadata": {
    "lines_to_end_of_cell_marker": 0,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Load the lab report we want to analyze\n",
    "try:\n",
    "    with open(\"../10-Pharma-QC/data/lab_report_04.txt\", \"r\") as f:\n",
    "        lab_report_text = f.read()\n",
    "    BATCH_ID = \"AP-2024-03-25-B004\"\n",
    "    print(f\"Loaded report for batch: {BATCH_ID}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Make sure the lab report from the previous lab exists at '../10-Pharma-QC/data/lab_report_04.txt'\")\n",
    "    lab_report_text = \"\"\n",
    "\n",
    "# --- SIMULATED AI OUTPUT ---\n",
    "# In a real lab, you would call your LLM here with the ACTIVE_PROMPT and lab_report_text.\n",
    "ai_analysis_result = {\n",
    "    \"summary\": \"The batch meets all specifications.\",\n",
    "    \"details\": \"However, the Dissolution Test result (81%) is within 5% of its lower specification limit (80%). The Salicylic Acid impurity (0.09%) is also close to its limit (<= 0.1%).\",\n",
    "    \"recommendation\": \"FLAG FOR HUMAN REVIEW\"\n",
    "}\n",
    "# --- END SIMULATION ---\n",
    "\n",
    "# Log the AI analysis event\n",
    "log_event(\n",
    "    event_type=\"AI_ANALYSIS_RUN\",\n",
    "    user=current_user,\n",
    "    prompt_version=ACTIVE_PROMPT_VERSION,\n",
    "    batch_id=BATCH_ID,\n",
    "    details=f\"AI recommendation: {ai_analysis_result['recommendation']}. Summary: {ai_analysis_result['summary']}\"\n",
    ")\n",
    "\n",
    "print(\"\\nAI Analysis Complete. Output:\")\n",
    "print(ai_analysis_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672661c4",
   "metadata": {},
   "source": [
    "## 5. Human-in-the-Loop: Review and Signature\n",
    "\n",
    "The AI has made a recommendation: \"FLAG FOR HUMAN REVIEW.\" It has not made the final decision. Now, a human analyst must review the AI's findings and make the final call. This is the **Human-in-the-Loop (HITL)** step. \n",
    "\n",
    "To make a final decision, the analyst must provide their \"electronic signature.\" In a real 21 CFR Part 11 system, this involves re-entering your password. We will simulate this by creating a hash of the user's password combined with the data being signed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_signature(user: str, password_input: str, data_to_sign: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a simulated electronic signature.\n",
    "    In a real system, you would use a secure, validated method.\n",
    "    \"\"\"\n",
    "    # Combine user, password, and data to create a unique signature hash\n",
    "    signature_string = f\"{user}:{password_input}:{data_to_sign}\"\n",
    "    return hashlib.sha256(signature_string.encode()).hexdigest()\n",
    "\n",
    "# The analyst reviews the AI's output and makes a decision.\n",
    "human_decision = \"I agree with the AI. The results are close to the limits. I will flag this for further investigation.\"\n",
    "final_classification = \"FLAGGED\"\n",
    "\n",
    "# The analyst must \"sign\" their decision.\n",
    "# getpass.getpass() securely prompts for a password without showing it on the screen.\n",
    "password = getpass.getpass(prompt=f\"User '{current_user}', please enter your password to sign: \")\n",
    "\n",
    "# We sign the combination of the batch ID and the final classification.\n",
    "data_being_signed = f\"{BATCH_ID}:{final_classification}\"\n",
    "user_signature = create_signature(current_user, password, data_being_signed)\n",
    "\n",
    "print(f\"\\nGenerated Signature: {user_signature}\")\n",
    "\n",
    "# Log the final human decision with the signature\n",
    "log_event(\n",
    "    event_type=\"HUMAN_APPROVAL\",\n",
    "    user=current_user,\n",
    "    batch_id=BATCH_ID,\n",
    "    details=f\"Final Classification: {final_classification}. Justification: {human_decision}\",\n",
    "    signature=user_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361fd616",
   "metadata": {},
   "source": [
    "## 6. Reviewing the Audit Trail\n",
    "\n",
    "The process is complete. Let's now act as an auditor and review the `audit_log.csv` file. \n",
    "\n",
    "A complete audit trail should tell a clear, chronological story of everything that happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f89df",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    audit_df = pd.read_csv(AUDIT_LOG_PATH)\n",
    "    print(\"--- Audit Log Review ---\")\n",
    "    # Display the full log for review\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', 1000)\n",
    "    pd.set_option('display.colheader_justify', 'center')\n",
    "    pd.set_option('display.precision', 3)\n",
    "    print(audit_df)\n",
    "except FileNotFoundError:\n",
    "    print(\"Audit log not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read audit log: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84fd21",
   "metadata": {},
   "source": [
    "### Exercise: Interpreting the Log\n",
    "\n",
    "**Your Task:** Look at the audit log above and answer the following questions, as if you were an auditor. \n",
    "\n",
    "1.  Who performed the final review of batch `AP-2024-03-25-B004`?\n",
    "2.  What version of the analysis prompt was used?\n",
    "3.  What was the final, human-approved classification for the batch?\n",
    "4.  Is the entire process from login to final signature captured?\n",
    "\n",
    "This exercise demonstrates how a well-maintained audit trail provides the traceability required for regulatory compliance.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you did not build a complex AI, but you performed an even more critical task: you built a **compliant process** around a simple AI. \n",
    "\n",
    "You have learned how to:\n",
    "1.  Create and maintain a detailed audit log for every system event.\n",
    "2.  Incorporate prompt versioning into your workflow.\n",
    "3.  Log the specific details of an AI analysis for traceability.\n",
    "4.  Implement a Human-in-the-Loop (HITL) decision step.\n",
    "5.  Generate and record a simulated electronic signature to ensure accountability.\n",
    "\n",
    "These governance principles are essential for deploying any AI system in a regulated pharmaceutical environment."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
