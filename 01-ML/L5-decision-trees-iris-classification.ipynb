{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccda858",
   "metadata": {},
   "source": [
    "---\n",
    "jupyter:\n",
    "  jupytext:\n",
    "    text_representation:\n",
    "      extension: .py\n",
    "      format_name: light\n",
    "      format_version: '1.5'\n",
    "      jupytext_version: 1.16.1\n",
    "  kernelspec:\n",
    "    display_name: Python 3 (ipykernel)\n",
    "    language: python\n",
    "    name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d97aeb8",
   "metadata": {},
   "source": [
    "# Lab: Decision Trees for Iris Classification\n",
    "\n",
    "**Goal:** In this lab, you will build a Decision Tree classifier and visualize it to understand how it makes decisions. Decision Trees are powerful because they are highly interpretable (\"white box\" models).\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Multi-class Classification:** Predicting one of more than two possible outcomes.\n",
    "- **Decision Tree:** A tree-like model that makes decisions based on feature values.\n",
    "- **Model Interpretability:** The ability to understand and explain how a model works.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "We need `scikit-learn` for the model and dataset, and `matplotlib` for plotting the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b08aa6",
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120c42f",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Iris Data\n",
    "\n",
    "The Iris dataset is a classic in machine learning. The goal is to classify a flower into one of three species (Setosa, Versicolour, Virginica) based on the length and width of its sepals and petals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483dc99",
   "metadata": {
    "tags": [
     "data_loading",
     "data_exploration"
    ]
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(\"---\" + \" Features (X) ---\")\n",
    "print(f\"Feature names: {iris.feature_names}\")\n",
    "print(f\"Sample data:\\n{X[:5]}\")\n",
    "\n",
    "print(\"\\n\" + \"---\" + \" Target (y) ---\")\n",
    "print(f\"Target names: {iris.target_names}\")\n",
    "print(f\"Sample labels: {y[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8a7f7",
   "metadata": {},
   "source": [
    "## 3. Prepare the Data\n",
    "\n",
    "We'll split the data into a training set and a testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13d024",
   "metadata": {
    "tags": [
     "data_preparation"
    ]
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cde6a2",
   "metadata": {},
   "source": [
    "## 4. Build and Train the Decision Tree\n",
    "\n",
    "We will create an instance of the `DecisionTreeClassifier` and fit it to our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660646",
   "metadata": {
    "tags": [
     "model_training"
    ]
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "# `max_depth` is a hyperparameter to prevent the tree from growing too complex and overfitting.\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "print(\"Training the Decision Tree...\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9958c7",
   "metadata": {},
   "source": [
    "## 5. Visualize the Decision Tree\n",
    "\n",
    "This is the most powerful feature of this model. We can directly see the rules it learned from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3622b8e",
   "metadata": {
    "tags": [
     "visualization"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf,\n",
    "          filled=True,\n",
    "          rounded=True,\n",
    "          class_names=iris.target_names,\n",
    "          feature_names=iris.feature_names)\n",
    "plt.title(\"Decision Tree for Iris Classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36814385",
   "metadata": {},
   "source": [
    "**How to Read the Tree:**\n",
    "- Each node represents a decision based on a feature (e.g., \"petal width (cm) <= 0.8\").\n",
    "- If the condition is true, you follow the left branch; if false, you follow the right branch.\n",
    "- **Gini:** The Gini impurity is a measure of how \"mixed\" the classes are in a node. A Gini of 0.0 means the node is perfectly pure (all samples belong to one class).\n",
    "- **Samples:** The number of training samples in that node.\n",
    "- **Value:** The distribution of samples across the classes.\n",
    "- **Class:** The majority class in that node.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Evaluate the Model\n",
    "\n",
    "Now let's see how well our interpretable model performs on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a6fc8",
   "metadata": {
    "tags": [
     "model_evaluation"
    ]
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy on Test Set: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dba9f38",
   "metadata": {},
   "source": [
    "**Analysis:** The Decision Tree is not only highly accurate on this dataset, but we can also explain to a non-expert *exactly* why it made a particular prediction by tracing the path down the tree. This is a major advantage in regulated industries or when explaining model decisions is important.\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this lab, you have built and visualized a Decision Tree classifier. You learned:\n",
    "1.  How to train a Decision Tree for a multi-class problem.\n",
    "2.  The key advantage of Decision Trees: their interpretability.\n",
    "3.  How to visualize the learned rules to understand the model's logic."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
